{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bbfbd-f7be-4113-ada2-3afb852c6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to find Table 3 and S4 DFT values\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Full paths to DFT directories (fhi-aims_data)\n",
    "dft_paths = {\n",
    "    '1H': r\"pyroxene_6/1_Hydrogen/final_fhi-aims_data/\",\n",
    "    '0H': r\"data_no_hydrogen/P6/fhi-aims_outputs/\",\n",
    "    '3H': r\"pyroxene_6/3_Hydrogen/final_fhi-aims_data/\"\n",
    "}\n",
    "\n",
    "def extract_dft_cpu_time(file_path):\n",
    "    lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find last occurrence of \"Detailed time accounting\"\n",
    "    for i in range(len(lines)-1, 0, -1):\n",
    "        if \"Detailed time accounting\" in lines[i]:\n",
    "            # The next line is the one we want\n",
    "            if i+1 < len(lines):\n",
    "                match = re.search(r'Total time\\s*:\\s*([\\d.]+)\\s*s', lines[i+1])\n",
    "                if match:\n",
    "                    return float(match.group(1))\n",
    "            break  # stop searching after last block\n",
    "    return None\n",
    "\n",
    "\n",
    "def process_dft_folder(base_path):\n",
    "    times = []\n",
    "    for i in range(1, 51):\n",
    "        opt_file = os.path.join(base_path, str(i), \"optimization.out\")\n",
    "        if os.path.exists(opt_file):\n",
    "            cpu_time = extract_dft_cpu_time(opt_file)\n",
    "            print(f\"{base_path}: {cpu_time:.2f} h\")\n",
    "            if cpu_time is not None:\n",
    "                times.append(cpu_time)\n",
    "    return times\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for name, path in dft_paths.items():\n",
    "    times = process_dft_folder(path)\n",
    "    if times:\n",
    "        stats = {\n",
    "            'Molecule': name,\n",
    "            'N Files': len(times),\n",
    "            'Total Time (h)': sum(times) / 3600,\n",
    "            'Average (h)': np.mean(times) / 3600,\n",
    "            'Max (h)': np.max(times) / 3600,\n",
    "            'Min (h)': np.min(times) / 3600,\n",
    "            'Std Dev (h)': np.std(times) / 3600,\n",
    "        }\n",
    "        results.append(stats)\n",
    "    else:\n",
    "        print(f\"No valid optimization.out files found for {name}\")\n",
    "\n",
    "# Export\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"DFT_CPU_Stats_P6.xlsx\", index=False)\n",
    "print(\"Exported DFT stats to DFT_CPU_Stats_P6.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d28e9f-ef5a-4648-ab86-b11c505f9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to find Table 3 and S4 TDDFT values\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Full paths to DFT directories (fhi-aims_data)\n",
    "dft_paths = {\n",
    "    '1H': r\"pyroxene_6/1_Hydrogen/final_fhi-aims_data/\",\n",
    "    '0H': r\"data_no_hydrogen/P6/fhi-aims_outputs/\",\n",
    "    '3H': r\"pyroxene_6/3_Hydrogen/final_fhi-aims_data/\"\n",
    "}\n",
    "\n",
    "def parse_cpu_time(line):\n",
    "    match = re.search(r'(\\d+)\\s+days\\s+(\\d+)\\s+hours\\s+(\\d+)\\s+minutes\\s+([\\d.]+)\\s+seconds', line)\n",
    "    if match:\n",
    "        days, hours, minutes, seconds = map(float, match.groups())\n",
    "        return days * 86400 + hours * 3600 + minutes * 60 + seconds\n",
    "    return None\n",
    "\n",
    "def process_folder(path):\n",
    "    times = []\n",
    "    for i in range(1, 51):  # out_1.log to out_50.log\n",
    "        file = os.path.join(path, f\"out_{i}.log\")\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                for line in f:\n",
    "                    if \"Job cpu time:\" in line:\n",
    "                        t = parse_cpu_time(line)\n",
    "                        if t is not None:\n",
    "                            times.append(t)\n",
    "                        break\n",
    "    return times\n",
    "\n",
    "# Collect data\n",
    "results = []\n",
    "\n",
    "for name, path in data_paths.items():\n",
    "    times = process_folder(path)\n",
    "    if times:\n",
    "        stats = {\n",
    "            'Molecule': name,\n",
    "            'N Files': len(times),\n",
    "            'Total Time (h)': sum(times) / 3600,\n",
    "            'Average (h)': np.mean(times) / 3600,\n",
    "            'Max (h)': np.max(times) / 3600,\n",
    "            'Min (h)': np.min(times) / 3600,\n",
    "            'Std Dev (h)': np.std(times) / 3600,\n",
    "        }\n",
    "        results.append(stats)\n",
    "    else:\n",
    "        print(f\"No logs found in {path}\")\n",
    "\n",
    "# Create DataFrame and export to Excel\n",
    "df = pd.DataFrame(results)\n",
    "output_file = \"TDDFT_CPU_Stats_P6.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(f\"Exported summary to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4b091-9d16-4306-846f-de2d3ac0bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to extract Figures 33 and S9\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, re\n",
    "from pathlib import Path\n",
    "from matplotlib import cm\n",
    "\n",
    "# ====================================================\n",
    "# Fixed parameters (modify as desired)\n",
    "# ====================================================\n",
    "target_gap = 5.7    # target HOMO–LUMO gap (eV)\n",
    "window = 1          # half‑width (eV)\n",
    "E_min = target_gap - window\n",
    "E_max = target_gap + window\n",
    "\n",
    "# ====================================================\n",
    "# Define base path for UV files.\n",
    "# (Assumes UV files are named like \"signals_1.txt\", \"signals_2.txt\", … \"signals_50.txt\".)\n",
    "# ====================================================\n",
    "uv_base_path = r\"pyroxene_4\\final_uv_data\"\n",
    "\n",
    "# Get list of all UV files in the directory.\n",
    "uv_files = glob.glob(uv_base_path + r\"\\signals_*.txt\")\n",
    "# Sort the file list numerically by extracting the number from the filename.\n",
    "uv_files.sort(key=lambda x: int(re.search(r\"signals_(\\d+)\", Path(x).stem).group(1)))\n",
    "selected_uv_files = uv_files  # Process all files\n",
    "\n",
    "# ====================================================\n",
    "# Define the common grid for Gaussian broadening.\n",
    "# x_total is in nm (as in your original code).\n",
    "# ====================================================\n",
    "x_total = np.linspace(1, 400, 10000)\n",
    "\n",
    "# ====================================================\n",
    "# Function: Process a single UV file.\n",
    "# ====================================================\n",
    "def process_uv_file(file, E_min, E_max):\n",
    "    \"\"\"\n",
    "    Reads a UV file (with two columns: wavelength in nm and intensity),\n",
    "    applies Gaussian broadening on the grid x_total (in nm) using your formula,\n",
    "    converts x_total to energy in eV using:\n",
    "          E (eV) = 1239.84 / (wavelength in nm),\n",
    "    reverses the arrays so that energy increases,\n",
    "    and restricts the result to the energy window [E_min, E_max].\n",
    "    \n",
    "    Returns:\n",
    "      E_window: 1D array of energy values (eV) within the window.\n",
    "      y_window: 1D array of the corresponding UV intensity (un-normalized) within the window.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(file)\n",
    "    x_nm = data[:, 0]   # wavelengths in nm\n",
    "    f = data[:, 1]      # intensities\n",
    "    y = np.zeros_like(x_total)\n",
    "    for i in range(len(f)):\n",
    "        y += (1.3062974e8) * (f[i] / (1e7/6400)) * np.exp(-(((1/x_total) - (1/x_nm[i]))/(1.0/6400))**2)\n",
    "    # Convert x_total (nm) to energy (eV)\n",
    "    E_uv = 1239.84 / x_total  \n",
    "    # Reverse arrays so that energy increases (since energy decreases as wavelength increases)\n",
    "    E_uv_sorted = E_uv[::-1]\n",
    "    y_sorted = y[::-1]\n",
    "    # Restrict to the energy window:\n",
    "    mask = (E_uv_sorted >= E_min) & (E_uv_sorted <= E_max)\n",
    "    E_window = E_uv_sorted[mask]\n",
    "    y_window = y_sorted[mask]\n",
    "    return E_window, y_window\n",
    "\n",
    "# ====================================================\n",
    "# Process all selected UV files and collect data.\n",
    "# ====================================================\n",
    "# Create an array for folder numbers using the numeric values extracted from file names.\n",
    "folder_numbers = []\n",
    "uv_data_list = []  # Will store each file's UV intensity (1D array over energy)\n",
    "for uv_file in selected_uv_files:\n",
    "    # Extract the folder number from the file name (e.g., \"signals_23.txt\" → 23)\n",
    "    file_stem = Path(uv_file).stem  # e.g., \"signals_23\"\n",
    "    m = re.search(r\"signals_(\\d+)\", file_stem)\n",
    "    if m:\n",
    "        folder_num = int(m.group(1))\n",
    "    else:\n",
    "        folder_num = 0\n",
    "    folder_numbers.append(folder_num)\n",
    "    \n",
    "    # Process the UV file for the specified energy window.\n",
    "    E_window, y_window = process_uv_file(uv_file, E_min, E_max)\n",
    "    uv_data_list.append(y_window)\n",
    "\n",
    "# Convert the list of UV intensity arrays into a 2D array.\n",
    "# Each row corresponds to one file.\n",
    "Z = np.array(uv_data_list)\n",
    "\n",
    "# Global min–max normalization across all UV data:\n",
    "global_min = np.min(Z)\n",
    "global_max = np.max(Z)\n",
    "Z_norm = (Z - global_min) / (global_max - global_min)\n",
    "\n",
    "# ====================================================\n",
    "# Obtain a common energy axis.\n",
    "# ====================================================\n",
    "# We assume all files produce the same energy axis; use the first file.\n",
    "E_common, _ = process_uv_file(selected_uv_files[0], E_min, E_max)\n",
    "\n",
    "# ====================================================\n",
    "# Create a meshgrid for the pseudocolor plot.\n",
    "# x-axis: the extracted folder numbers, y-axis: energy (eV)\n",
    "# ====================================================\n",
    "n_folders = len(folder_numbers)\n",
    "n_energy = Z_norm.shape[1]\n",
    "X = np.repeat(np.array(folder_numbers).reshape(n_folders, 1), n_energy, axis=1)\n",
    "Y = np.repeat(np.array(E_common).reshape(1, n_energy), n_folders, axis=0)\n",
    "\n",
    "# ====================================================\n",
    "# Plot the pseudocolor graph.\n",
    "# ====================================================\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.pcolormesh(X, Y, Z_norm, cmap=cm.coolwarm, shading='auto')\n",
    "plt.xlabel(\"Isomer Number\")\n",
    "plt.ylabel(\"Energy (eV)\")\n",
    "plt.colorbar(label=\"Normalized UV Intensity\")\n",
    "plt.title(\"Pseudocolour of UV Intensity vs. Isomer Number and Energy (eV) (Pyroxene 4 (2H))\", fontsize=12)\n",
    "plt.axhline(y=5.7, color='green', linestyle=\"--\")\n",
    "\n",
    "# Set x-axis ticks so that every other folder number is labeled.\n",
    "xticks = np.arange(min(folder_numbers), max(folder_numbers)+1, 2)\n",
    "plt.xticks(xticks)\n",
    "\n",
    "plt.savefig(\"pseudocolour_P4.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1049f33-09ba-4d42-9a87-838442f10386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example script to extract Figure 36\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define paths to directories and files\n",
    "optimisation_root_dir = Path(r\"pyroxene_4\\final_fhi-aims_data\")\n",
    "excel_file_path = r\"New Average\\UV intensities P4.xlsx\"\n",
    "\n",
    "# Step 2: Get parameters for HOMO-n and LUMO+x from user\n",
    "n = int(input(\"Enter the value of n for HOMO-n: \"))\n",
    "x = int(input(\"Enter the value of x for LUMO+x: \"))\n",
    "\n",
    "# Step 3: Load intensity data from Excel and ensure folder names are strings\n",
    "df_intensity = pd.read_excel(excel_file_path)\n",
    "df_intensity[\"File Number\"] = df_intensity[\"File Number\"].astype(str)\n",
    "\n",
    "# Step 4: Prepare lists to store data for plotting and labelling\n",
    "file_numbers = []\n",
    "gap_values = []\n",
    "intensity_values = []\n",
    "\n",
    "# Function to parse the eigenvalue block from an optimization.out file content\n",
    "def parse_eigenvalue_block(content):\n",
    "    eigenvalue_data = []\n",
    "    # Find the header (searching from the end of the file)\n",
    "    state_header_index = next(\n",
    "        (i for i, line in enumerate(reversed(content)) if \"State    Occupation    Eigenvalue [Ha]\" in line), None\n",
    "    )\n",
    "    if state_header_index is not None:\n",
    "        state_header_index = len(content) - state_header_index - 1\n",
    "        eigenvalue_block = content[state_header_index:]\n",
    "        for line in eigenvalue_block[1:]:  # Skip the header line\n",
    "            tokens = line.split()\n",
    "            # Check if the line has 4 tokens and that the first 3 can be parsed as numbers\n",
    "            if len(tokens) == 4 and all(c.replace('.', '', 1).replace('-', '', 1).isdigit() for c in tokens[:3]):\n",
    "                try:\n",
    "                    eigenvalue_data.append([int(tokens[0]), float(tokens[1]), float(tokens[2]), float(tokens[3])])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return pd.DataFrame(eigenvalue_data, columns=[\"State\", \"Occupation\", \"Eigenvalue [Ha]\", \"Eigenvalue [eV]\"])\n",
    "    return None\n",
    "\n",
    "# Step 5: Extract gap values and match with intensity data for each folder\n",
    "for opt_folder in optimisation_root_dir.iterdir():\n",
    "    if opt_folder.is_dir():\n",
    "        opt_file = opt_folder / \"optimization.out\"\n",
    "        folder_name = opt_folder.name  # This will be our label\n",
    "        \n",
    "        if opt_file.exists():\n",
    "            with open(opt_file, 'r') as f:\n",
    "                content = f.readlines()\n",
    "                \n",
    "                eigenvalue_df = parse_eigenvalue_block(content)\n",
    "                if eigenvalue_df is not None:\n",
    "                    # Identify HOMO: last state with full occupation (2.00000)\n",
    "                    homo_row = eigenvalue_df[eigenvalue_df[\"Occupation\"] == 2.00000].iloc[-1]\n",
    "                    # Identify LUMO: first state with occupation less than 2.00000\n",
    "                    lumo_row = eigenvalue_df[eigenvalue_df[\"Occupation\"] < 2.00000].iloc[0]\n",
    "                    \n",
    "                    homo_index = homo_row[\"State\"]\n",
    "                    lumo_index = lumo_row[\"State\"]\n",
    "                    \n",
    "                    # Calculate energies for HOMO-n and LUMO+x if available\n",
    "                    homo_n_energy = eigenvalue_df.loc[eigenvalue_df[\"State\"] == homo_index - n, \"Eigenvalue [eV]\"].values\n",
    "                    lumo_x_energy = eigenvalue_df.loc[eigenvalue_df[\"State\"] == lumo_index + x, \"Eigenvalue [eV]\"].values\n",
    "                    \n",
    "                    if homo_n_energy.size > 0 and lumo_x_energy.size > 0:\n",
    "                        gap = lumo_x_energy[0] - homo_n_energy[0]\n",
    "                        gap_values.append(gap)\n",
    "                        file_numbers.append(folder_name)\n",
    "                        \n",
    "                        # Find matching intensity for the folder from the Excel data\n",
    "                        if folder_name in df_intensity[\"File Number\"].values:\n",
    "                            intensity = df_intensity.loc[df_intensity[\"File Number\"] == folder_name, \"Peak Intensity (Mb)\"].values\n",
    "                            if intensity.size > 0:\n",
    "                                intensity_values.append(intensity[0])\n",
    "                            else:\n",
    "                                print(f\"No matching intensity found for folder {folder_name}\")\n",
    "                        else:\n",
    "                            print(f\"No matching intensity found for folder {folder_name}\")\n",
    "                    else:\n",
    "                        print(f\"Gap calculation failed for folder {folder_name}\")\n",
    "                else:\n",
    "                    print(f\"No eigenvalue block found in folder {folder_name}\")\n",
    "        else:\n",
    "            print(f\"Optimization file not found in folder {folder_name}\")\n",
    "\n",
    "# Step 6: Create a DataFrame for plotting and labelling\n",
    "df_plot = pd.DataFrame({\n",
    "    \"File Number\": file_numbers,\n",
    "    \"Gap Energy\": gap_values,\n",
    "    \"Peak Intensity (Mb)\": intensity_values\n",
    "})\n",
    "\n",
    "# Step 7: Plot the results with labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_plot[\"Gap Energy\"], df_plot[\"Peak Intensity (Mb)\"]/4, c=\"blue\", edgecolor=\"black\")\n",
    "plt.title(f\"HOMO-{n} to LUMO+{x} Gap vs Intensity (P4 + 2H)\")\n",
    "plt.xlabel(\"Gap Energy (eV)\")\n",
    "plt.ylabel(r'$\\sigma$ / Si atom [Mb]', fontweight='bold')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add annotation for each data point using the file number as the label\n",
    "for idx, row in df_plot.iterrows():\n",
    "    plt.annotate(str(row[\"File Number\"]),\n",
    "                 (row[\"Gap Energy\"], row[\"Peak Intensity (Mb)\"]/4),\n",
    "                 textcoords=\"offset points\", xytext=(5, 5), fontsize=8)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dded7-cc80-4cec-a335-6b7c0a55c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to extract peak and average intensity data used in Figures 36-37\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Base path to your files\n",
    "base_path = (r\"C:/Users/charl/OneDrive - Imperial College London/Chemistry/Y4 Chemistry/Master’s Project/Data_UV_Hydrogenated_Pyroxenes/my_calculations/pyroxene_6/3_Hydrogen/final_uv_data/\")\n",
    "\n",
    "def gaussian_broadening(x_nm, f, x_total, sigma):\n",
    "    \"\"\" Apply Gaussian broadening in the inverse-micron domain. \"\"\"\n",
    "    x_file_inv = 1e3 / x_nm   # Convert wavelengths to inverse microns\n",
    "    y = np.zeros_like(x_total)\n",
    "\n",
    "    # Apply Gaussian broadening to each peak\n",
    "    for i in range(len(f)):\n",
    "        y += f[i] * np.exp(-((x_total - x_file_inv[i]) / sigma) ** 2)\n",
    "\n",
    "    # Apply scaling factor for correct intensity units\n",
    "    factor = 1.3062974e8 / (1e7 / 6200)\n",
    "    y *= factor\n",
    "\n",
    "    # Convert intensity to Megabarns (Mb)\n",
    "    y *= 3.82353216 * 10**(-21) * 10**(18)\n",
    "\n",
    "    return y\n",
    "\n",
    "def extract_peak_and_avg_intensity(y, x_total, peak_range=(4.08, 4.82), avg_bounds=(4.08, 4.82)):\n",
    "    \"\"\" \n",
    "    Extracts peak intensity and calculates average intensity within a fixed range (avg_bounds).\n",
    "    \n",
    "    Parameters:\n",
    "        y          : broadened intensity array\n",
    "        x_total    : x-axis grid in inverse microns (sorted ascending)\n",
    "        peak_range : Tuple (lower, upper) for valid peak selection range in μm⁻¹\n",
    "        avg_bounds : Tuple (lower, upper) for average intensity calculation range\n",
    "    \n",
    "    Returns:\n",
    "        peak_intensity : Maximum intensity within valid peak range (Mb)\n",
    "        peak_wavenumber: Wavenumber where peak occurs (μm⁻¹)\n",
    "        avg_intensity  : Average intensity between avg_bounds (Mb)\n",
    "    \"\"\"\n",
    "    # Get peak within the desired range\n",
    "    peak_low_idx = np.searchsorted(x_total, peak_range[0])\n",
    "    peak_high_idx = np.searchsorted(x_total, peak_range[1])\n",
    "    \n",
    "    if peak_high_idx > peak_low_idx:\n",
    "        valid_region_intensity = y[peak_low_idx:peak_high_idx]\n",
    "        valid_region_x = x_total[peak_low_idx:peak_high_idx]\n",
    "        peak_idx = np.argmax(valid_region_intensity)\n",
    "        peak_intensity = valid_region_intensity[peak_idx]\n",
    "        peak_wavenumber = valid_region_x[peak_idx]\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    # Now compute average intensity over the fixed window: 4.08–4.82 μm⁻¹\n",
    "    avg_low_idx = np.searchsorted(x_total, avg_bounds[0])\n",
    "    avg_high_idx = np.searchsorted(x_total, avg_bounds[1])\n",
    "\n",
    "    if avg_high_idx > avg_low_idx:\n",
    "        avg_region_intensity = y[avg_low_idx:avg_high_idx]\n",
    "        avg_region_x = x_total[avg_low_idx:avg_high_idx]\n",
    "        avg_intensity = np.trapz(avg_region_intensity, avg_region_x) / (avg_bounds[1] - avg_bounds[0])\n",
    "    else:\n",
    "        avg_intensity = np.nan\n",
    "\n",
    "    return peak_intensity, peak_wavenumber, avg_intensity\n",
    "\n",
    "\n",
    "# Get all the relevant files and sort them\n",
    "all_files = glob.glob(base_path + \"signals_*.txt\")\n",
    "all_files.sort()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Define x_total grid using inverse microns\n",
    "wavelength_range = np.linspace(175, 250, 1000)  # in nm\n",
    "x_ev = 1239.84 / wavelength_range\n",
    "x_ev_corrected = x_ev + 0.1  # Small energy correction\n",
    "wavelength_corrected = 1239.84 / x_ev_corrected  # Convert back to nm\n",
    "x_total_unsorted = 1e3 / wavelength_corrected  # Convert to inverse microns\n",
    "x_total = np.sort(x_total_unsorted)\n",
    "\n",
    "sigma = 0.081  # Gaussian broadening width in μm⁻¹\n",
    "\n",
    "# Process each file\n",
    "for file in all_files:\n",
    "    data = np.loadtxt(file)\n",
    "    x_nm = data[:, 0]\n",
    "    f = data[:, 1]\n",
    "    \n",
    "    # Apply Gaussian broadening\n",
    "    y = gaussian_broadening(x_nm, f, x_total, sigma)\n",
    "    \n",
    "    # Extract peak and average intensity **only if peak is within 4.1–4.8 μm⁻¹**\n",
    "    peak_intensity, peak_wavenumber, avg_intensity = extract_peak_and_avg_intensity(y, x_total, peak_range=(4.08, 4.82))\n",
    "\n",
    "    if not np.isnan(peak_wavenumber):\n",
    "        peak_wavenumber_rounded = round(peak_wavenumber, 2)\n",
    "    else:\n",
    "        peak_wavenumber_rounded = np.nan\n",
    "\n",
    "    # Extract the file number from the filename\n",
    "    file_number = re.search(r\"signals_(\\d+)\\.txt\", Path(file).name).group(1)\n",
    "    results.append((int(file_number), peak_intensity, avg_intensity, peak_wavenumber_rounded))\n",
    "\n",
    "# Create a DataFrame with the updated column names\n",
    "df = pd.DataFrame(results, columns=['File Number', 'Peak Intensity (Mb)', \n",
    "                                    'Avg Intensity (Mb)', 'Peak Position (Wavenumber, μm⁻¹)'])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(\"UV intensities P4.xlsx\", index=False)\n",
    "print(\"Extracted data written to UV intensities P4 .xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8bacf-e5dc-47a5-bd5c-d8ca72373a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to extract Figure 37\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load extracted Mg-H distances from CSV\n",
    "distances_file = \"mg_h_distances_P4.csv\"  # Ensure this file is generated from the previous script\n",
    "df_distances = pd.read_csv(distances_file)\n",
    "\n",
    "# Step 2: Load intensity data from Excel\n",
    "intensity_file_path = r\"New Average\\UV intensities P4.xlsx\"\n",
    "df_intensity = pd.read_excel(intensity_file_path)\n",
    "\n",
    "# Step 3: Ensure folder names are strings for matching\n",
    "df_distances[\"Structure\"] = df_distances[\"Structure\"].astype(str)\n",
    "df_intensity[\"File Number\"] = df_intensity[\"File Number\"].astype(str)\n",
    "\n",
    "# Step 4: Merge datasets on folder names\n",
    "merged_df = df_distances.merge(df_intensity, left_on=\"Structure\", right_on=\"File Number\", how=\"inner\")\n",
    "\n",
    "# Step 5: Extract necessary columns\n",
    "x_values = merged_df[\"Smallest_Mg_H_Distance\"]  # X-axis: second smallest Mg-H distance\n",
    "y_values = merged_df[\"Peak Intensity (Mb)\"]  # Y-axis: intensity\n",
    "\n",
    "# Step 6: Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_values, y_values/4, c=\"blue\", edgecolor=\"black\")\n",
    "plt.title(\"Smallest Mg-H Distance vs Intensity (P4 + 2H)\")\n",
    "plt.xlabel(\"Smallest Mg-H Distance (Å)\")\n",
    "plt.ylabel(\"Intensity (Mb/Si atom)\")\n",
    "plt.grid(True)\n",
    "\n",
    "for idx, row in merged_df.iterrows():\n",
    "    plt.annotate(str(row[\"File Number\"]), \n",
    "                 (row[\"Smallest_Mg_H_Distance\"], row[\"Peak Intensity (Mb)\"]/4),\n",
    "                 textcoords=\"offset points\", xytext=(5, 5), fontsize=8)\n",
    "\n",
    "plt.savefig(\"Mg_H_distance_example.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9bc28-db89-4c5b-afe7-1ba54b16a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script producing dataset for Figure 37\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ase import Atoms\n",
    "from ase.io import read\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to calculate bond length between two atoms\n",
    "def bond_length(atom1, atom2):\n",
    "    return np.linalg.norm(atom1.position - atom2.position)\n",
    "\n",
    "# Function to calculate average, smallest, and second smallest Mg-H bond lengths\n",
    "def mg_h_distances(atoms, element1=\"Mg\", element2=\"H\"):\n",
    "    bond_lengths = []  # List to store Mg-H bond lengths\n",
    "    \n",
    "    for i, atom in enumerate(atoms):\n",
    "        if atom.symbol == element1:  # Only calculate for Mg atoms\n",
    "            for j, other_atom in enumerate(atoms):\n",
    "                if i != j and other_atom.symbol == element2:  # Look for H atoms\n",
    "                    length = bond_length(atom, other_atom)\n",
    "                    bond_lengths.append(length)  # Store bond length\n",
    "\n",
    "    if bond_lengths:\n",
    "        bond_lengths.sort()  # Sort distances in ascending order\n",
    "        avg_distance = np.mean(bond_lengths)  # Calculate average bond length\n",
    "        smallest = bond_lengths[0] if len(bond_lengths) > 0 else None\n",
    "        second_smallest = bond_lengths[1] if len(bond_lengths) > 1 else None\n",
    "        return avg_distance, smallest, second_smallest\n",
    "    else:\n",
    "        return None, None, None  # Return None if no Mg-H bonds exist\n",
    "\n",
    "# Step 1: Define the root directory where your subfolders are located\n",
    "optimisation_root_dir = Path(r\"pyroxene_4\\final_fhi-aims_data\")\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = []\n",
    "\n",
    "# Step 2: Iterate over the folders to find and process each .xyz file\n",
    "for opt_folder in optimisation_root_dir.iterdir():  # Loop through all folders in the root directory\n",
    "    if opt_folder.is_dir():  # Ensure it's a directory\n",
    "        xyz_file = opt_folder / f\"final_{opt_folder.name}.xyz\"  # Match the final_x.xyz file based on folder name\n",
    "        \n",
    "        if xyz_file.exists():\n",
    "            print(f\"Processing {xyz_file}\")\n",
    "            \n",
    "            # Manually read and process the .xyz file\n",
    "            with open(xyz_file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "                # Skip the first line (energy) and use the second line (atom count)\n",
    "                num_atoms = int(lines[1].strip())\n",
    "                \n",
    "                # Extract atomic coordinates starting from the third line\n",
    "                atom_data = lines[2:2 + num_atoms]\n",
    "                \n",
    "                # Convert to ASE Atoms object\n",
    "                symbols = []\n",
    "                positions = []\n",
    "                for line in atom_data:\n",
    "                    parts = line.split()\n",
    "                    symbols.append(parts[0])  # First column is element symbol\n",
    "                    positions.append([float(parts[1]), float(parts[2]), float(parts[3])])  # X, Y, Z coordinates\n",
    "                \n",
    "                atoms = Atoms(symbols=symbols, positions=positions)\n",
    "                \n",
    "                # Step 4: Calculate Mg-H bond distances\n",
    "                avg_distance, smallest, second_smallest = mg_h_distances(atoms, element1=\"Mg\", element2=\"H\")\n",
    "                \n",
    "                if avg_distance is not None:\n",
    "                    results.append([opt_folder.name, avg_distance, smallest, second_smallest])\n",
    "                    print(f\"Avg Mg-H: {avg_distance:.2f} Å, Smallest: {smallest:.2f} Å, 2nd Smallest: {second_smallest:.2f} Å\")\n",
    "                else:\n",
    "                    print(f\"No Mg-H bonds found in {opt_folder.name}\")\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "        else:\n",
    "            print(f\"XYZ file not found in folder {opt_folder.name}\")\n",
    "\n",
    "# Step 5: Convert results to a dataset-like format\n",
    "results_df = pd.DataFrame(results, columns=[\"Structure\", \"Average_Mg_H_Distance\", \"Smallest_Mg_H_Distance\", \"Second_Smallest_Mg_H_Distance\"])\n",
    "results_df.to_csv(\"mg_h_distances_P4.csv\", index=False)  # Save as CSV\n",
    "print(\"Results saved to 'mg_h_distances_P4.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
